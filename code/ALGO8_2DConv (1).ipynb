{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport os\nimport numpy as np \nimport pandas as pd\nfrom numpy import mean\nfrom numpy import std\nfrom numpy import dstack\nfrom numpy import concatenate\nfrom pandas import read_csv\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import Dropout\nfrom keras.layers import LSTM\nfrom keras.utils import to_categorical\nfrom matplotlib import pyplot\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nimport keras\nimport tensorflow as tf\nimport scipy.stats as stats\nfrom tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\nimport tensorflow as tf\nimport keras.backend.tensorflow_backend as tfback\nfrom keras.layers import  Reshape\nfrom keras.layers import Conv2D, MaxPooling2D\ndef _get_available_gpus():\n    \"\"\"Get a list of available gpu devices (formatted as strings).\n\n    # Returns\n        A list of available GPU devices.\n    \"\"\"\n    #global _LOCAL_DEVICES\n    if tfback._LOCAL_DEVICES is None:\n        devices = tf.config.list_logical_devices()\n        tfback._LOCAL_DEVICES = [x.name for x in devices]\n    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n\ntfback._get_available_gpus = _get_available_gpus\n# from keras import backend as K\n# K.tensorflow_backend._get_available_gpus()\n# config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n# sess = tf.Session(config=config) \n# keras.backend.set_session(sess)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":34,"outputs":[{"output_type":"stream","text":"[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 12396023224496456239\n, name: \"/device:XLA_CPU:0\"\ndevice_type: \"XLA_CPU\"\nmemory_limit: 17179869184\nlocality {\n}\nincarnation: 15805070505137750797\nphysical_device_desc: \"device: XLA_CPU device\"\n, name: \"/device:GPU:0\"\ndevice_type: \"GPU\"\nmemory_limit: 15870492672\nlocality {\n  bus_id: 1\n  links {\n  }\n}\nincarnation: 1487173218056091133\nphysical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n, name: \"/device:XLA_GPU:0\"\ndevice_type: \"XLA_GPU\"\nmemory_limit: 17179869184\nlocality {\n}\nincarnation: 15834772858120117694\nphysical_device_desc: \"device: XLA_GPU device\"\n]\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"os.chdir('/kaggle/input/smartphone-and-smartwatch-activity-and-biometrics/wisdm-dataset/wisdm-dataset/raw/')\n\n# %% [code]\n\n# load a single file as a numpy array\ndef load_file(filepath):\n    dataframe = read_csv(filepath,sep = ',', header=None)\n    return dataframe.to_numpy()\n \n# load a list of files and return as a 3d numpy array\ndef load_group(filenames, prefix=''):\n    loaded = list()\n    for name in filenames:\n        data = load_file(prefix + name)\n        loaded.append(data)\n    # stack group so that features are the 3rd dimension\n    loaded = concatenate(loaded)\n    return loaded\n \n# load a dataset group, such as train or test\ndef load_dataset_group(sample='', prefix='',sensor='',recorder=''):\n#     sensor = 'accel'\n#     recorder = 'phone'\n    filepath = recorder +'/'+ sensor +'/'\n    # load all 9 files as a single array\n    filenames = list()\n    # total acceleration\n   \n    filenames += ['data_'+sample+'_'+sensor+'_'+recorder+'.txt']\n            \n    for filename in filenames:\n        df = load_file(filepath+filename)\n    return df\n \n# load the dataset, returns train and test X and y elements\ndef load_dataset(prefix=''):\n    # load all train\n    prefix = ''\n    dataSampleTrain = list()\n    recorder = ['phone','watch']\n    sensor  = ['accel','gyro']\n    for i in range (1600,1620):\n        size = 99999\n        data = list()\n        for rec in recorder:\n            for sens in sensor:\n                DS = load_dataset_group(str(i), prefix,sens,rec)\n                size = min(size,DS.shape[0])\n                data.append(DS)\n        \n        \n            \n        for i in range(4):\n            data[i] = data[i][:size]\n        dataSampleTrain.append(concatenate(data, axis = 1))\n        \n    \n    dataSampleTrain = concatenate(dataSampleTrain)\n    Traindf = pd.DataFrame(dataSampleTrain)\n    #Traindf.to_csv('TrainDF.csv')\n    \n    dataSampleTest = list() \n    for i in range (1620,1634):\n        size = 99999\n        data = list()\n        for rec in recorder:\n            for sens in sensor:\n                DS = load_dataset_group(str(i), prefix,sens,rec)\n                size = min(size,DS.shape[0])\n                data.append(DS)\n        \n        \n            \n        for i in range(4):\n            data[i] = data[i][:size]\n        dataSampleTest.append(concatenate(data, axis = 1))\n        \n    \n    dataSampleTest = concatenate(dataSampleTest)\n    Testdf = pd.DataFrame(dataSampleTest)\n    #Traindf.to_csv('TrainDF.csv')\n    \n    return Traindf,Testdf\ntrainDS,testDS = load_dataset('')\ntrainDS.head()","execution_count":35,"outputs":[{"output_type":"execute_result","execution_count":35,"data":{"text/plain":"     0  1                2         3        4            5     6  7   \\\n0  1600  A  252207666810782 -0.364761   8.7935   1.0550842;  1600  A   \n1  1600  A  252207717164786  -0.87973  9.76878   1.0169983;  1600  A   \n2  1600  A  252207767518790    2.0015  11.1091    2.619156;  1600  A   \n3  1600  A  252207817872794  0.450623  12.6516  0.18455505;  1600  A   \n4  1600  A  252207868226798  -2.16435  13.9284  -4.4224854;  1600  A   \n\n                8         9   ...              14       15        16  \\\n0  252207918580802  -0.85321  ...  90426708196641  7.09162 -0.591667   \n1  252207968934806 -0.875137  ...  90426757696641  4.97276 -0.158317   \n2  252208019288809 -0.720169  ...  90426807196641  3.25372 -0.191835   \n3  252208069642813  -0.57164  ...  90426856696641  2.80122 -0.155922   \n4  252208119996817 -0.380493  ...  90426906196641  3.77087  -1.05135   \n\n           17    18 19              20         21        22              23  \n0   8.195502;  1600  A  90426757696641   0.314944  -1.02228     -0.3099616;  \n1  6.6967316;  1600  A  90426807196641   0.387382 -0.618541   -0.048971802;  \n2   6.107758;  1600  A  90426856696641  0.0709985  -0.20948     -0.1959783;  \n3   5.997625;  1600  A  90426906196641  0.0379753  0.254976     -0.1565635;  \n4   7.731027;  1600  A  90426955696641  0.0731291  0.719431  -0.0010349044;  \n\n[5 rows x 24 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1600</td>\n      <td>A</td>\n      <td>252207666810782</td>\n      <td>-0.364761</td>\n      <td>8.7935</td>\n      <td>1.0550842;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>252207918580802</td>\n      <td>-0.85321</td>\n      <td>...</td>\n      <td>90426708196641</td>\n      <td>7.09162</td>\n      <td>-0.591667</td>\n      <td>8.195502;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>90426757696641</td>\n      <td>0.314944</td>\n      <td>-1.02228</td>\n      <td>-0.3099616;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1600</td>\n      <td>A</td>\n      <td>252207717164786</td>\n      <td>-0.87973</td>\n      <td>9.76878</td>\n      <td>1.0169983;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>252207968934806</td>\n      <td>-0.875137</td>\n      <td>...</td>\n      <td>90426757696641</td>\n      <td>4.97276</td>\n      <td>-0.158317</td>\n      <td>6.6967316;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>90426807196641</td>\n      <td>0.387382</td>\n      <td>-0.618541</td>\n      <td>-0.048971802;</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1600</td>\n      <td>A</td>\n      <td>252207767518790</td>\n      <td>2.0015</td>\n      <td>11.1091</td>\n      <td>2.619156;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>252208019288809</td>\n      <td>-0.720169</td>\n      <td>...</td>\n      <td>90426807196641</td>\n      <td>3.25372</td>\n      <td>-0.191835</td>\n      <td>6.107758;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>90426856696641</td>\n      <td>0.0709985</td>\n      <td>-0.20948</td>\n      <td>-0.1959783;</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1600</td>\n      <td>A</td>\n      <td>252207817872794</td>\n      <td>0.450623</td>\n      <td>12.6516</td>\n      <td>0.18455505;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>252208069642813</td>\n      <td>-0.57164</td>\n      <td>...</td>\n      <td>90426856696641</td>\n      <td>2.80122</td>\n      <td>-0.155922</td>\n      <td>5.997625;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>90426906196641</td>\n      <td>0.0379753</td>\n      <td>0.254976</td>\n      <td>-0.1565635;</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1600</td>\n      <td>A</td>\n      <td>252207868226798</td>\n      <td>-2.16435</td>\n      <td>13.9284</td>\n      <td>-4.4224854;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>252208119996817</td>\n      <td>-0.380493</td>\n      <td>...</td>\n      <td>90426906196641</td>\n      <td>3.77087</td>\n      <td>-1.05135</td>\n      <td>7.731027;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>90426955696641</td>\n      <td>0.0731291</td>\n      <td>0.719431</td>\n      <td>-0.0010349044;</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 24 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess and load X\ndef X_pre(trainDS):\n    \n    \n    cols = [5,11,17,23]\n    for col in cols:\n            trainDS[trainDS.columns[col]] = trainDS[trainDS.columns[col]].str.replace(';','').astype(float)\n    \n    columns = ['x','y','z']\n    X = pd.DataFrame(data=None, columns=columns)\n    X['x'] = trainDS[3]+trainDS[9]+trainDS[15]+trainDS[21]\n    X['y'] = trainDS[4]+trainDS[10]+trainDS[16]+trainDS[22]\n    X['z'] = trainDS[5]+trainDS[11]+trainDS[17]+trainDS[23]\n    \n    # train the normalization\n    scaler = StandardScaler()\n    X = scaler.fit_transform(X)\n\n    return X\n\ntrainX = X_pre(trainDS)\ntestX = X_pre(testDS)","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess and load Y\n\ndef Y_pre(trainDS):\n    cols = [1,7,13,19]\n    Y = np.zeros((trainDS.shape[0]),dtype=int)\n\n    lable_encoder = LabelEncoder()\n\n    pos = list()\n    for col in cols:\n        y = trainDS[col]\n        y = lable_encoder.fit_transform(y)\n        pos.append(y)\n\n    pos = np.vstack((pos))\n\n    for i in range (trainDS.shape[0]):\n        Y[i] = np.bincount(pos[:,i]).argmax()\n\n    return Y\n\ntrainY = Y_pre(trainDS)\ntestY = Y_pre(testDS)","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Fs=20\nframe_size = Fs*4 #80\nhop_size = Fs*2 #40","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_frames(df,tag, frame_size, hop_size):\n    \n    N_FEATURES = df.shape[1]\n    frames = []\n    labels = []\n    for i in range(0,len(df )- frame_size, hop_size):\n        x1 = df[i: i+frame_size,0]\n        y1 = df[i: i+frame_size,1]\n        z1 = df[i: i+frame_size,2]\n        \n        label = stats.mode(tag[i: i+frame_size])[0][0]\n        frames.append([x1,y1,z1])\n        labels.append(label)\n        \n    frames = np.asarray(frames).reshape(-1, frame_size, N_FEATURES)\n    labels = np.asarray(labels)\n    \n    return frames, labels","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.device('/device:GPU:0'):\n    train_X,train_Y = get_frames(trainX,trainY, frame_size, hop_size)\n    test_X,test_Y = get_frames(testX,testY, frame_size, hop_size)","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nx_train,y_train,x_test,y_test = trainx,train_Y,testx,test_Y\nwith tf.device('/device:GPU:0'):\n    #batch_size = 12\n    model = Sequential()\n    model.add(Conv2D(256, (2,2), activation = 'relu', input_shape = x_train[0].shape))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(512, (2,2), activation = 'relu'))\n    model.add(Dropout(0.5))\n\n    model.add(Flatten())\n\n    model.add(Dense(1024, activation = 'relu'))\n    model.add(Dropout(0.5))\n\n    model.add(Dense(18, activation='softmax'))\n    \n    model.compile(optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]) \n    history = model.fit(x_train, y_train, epochs = 25, validation_data=(x_test, y_test), verbose=1 )\n    ","execution_count":41,"outputs":[{"output_type":"stream","text":"Train on 31934 samples, validate on 23638 samples\nEpoch 1/25\n31934/31934 [==============================] - 23s 706us/step - loss: 1.6891 - accuracy: 0.4236 - val_loss: 2.5450 - val_accuracy: 0.2977\nEpoch 2/25\n31934/31934 [==============================] - 22s 688us/step - loss: 1.0563 - accuracy: 0.6378 - val_loss: 3.2827 - val_accuracy: 0.2982\nEpoch 3/25\n31934/31934 [==============================] - 22s 697us/step - loss: 0.7637 - accuracy: 0.7363 - val_loss: 3.6775 - val_accuracy: 0.2937\nEpoch 4/25\n31934/31934 [==============================] - 22s 683us/step - loss: 0.5952 - accuracy: 0.7976 - val_loss: 3.8115 - val_accuracy: 0.2884\nEpoch 5/25\n31934/31934 [==============================] - 22s 685us/step - loss: 0.4879 - accuracy: 0.8351 - val_loss: 4.2079 - val_accuracy: 0.3010\nEpoch 6/25\n31934/31934 [==============================] - 22s 694us/step - loss: 0.4056 - accuracy: 0.8637 - val_loss: 4.9716 - val_accuracy: 0.2878\nEpoch 7/25\n31934/31934 [==============================] - 22s 681us/step - loss: 0.3583 - accuracy: 0.8781 - val_loss: 5.1763 - val_accuracy: 0.2890\nEpoch 8/25\n31934/31934 [==============================] - 22s 690us/step - loss: 0.3172 - accuracy: 0.8945 - val_loss: 5.5344 - val_accuracy: 0.2933\nEpoch 9/25\n31934/31934 [==============================] - 22s 690us/step - loss: 0.2875 - accuracy: 0.9033 - val_loss: 5.8821 - val_accuracy: 0.2882\nEpoch 10/25\n31934/31934 [==============================] - 22s 684us/step - loss: 0.2623 - accuracy: 0.9113 - val_loss: 6.3931 - val_accuracy: 0.2978\nEpoch 11/25\n31934/31934 [==============================] - 22s 692us/step - loss: 0.2527 - accuracy: 0.9154 - val_loss: 6.3640 - val_accuracy: 0.2985\nEpoch 12/25\n31934/31934 [==============================] - 22s 685us/step - loss: 0.2310 - accuracy: 0.9234 - val_loss: 6.3236 - val_accuracy: 0.2917\nEpoch 13/25\n31934/31934 [==============================] - 22s 682us/step - loss: 0.2134 - accuracy: 0.9299 - val_loss: 6.7085 - val_accuracy: 0.2980\nEpoch 14/25\n31934/31934 [==============================] - 22s 694us/step - loss: 0.1998 - accuracy: 0.9342 - val_loss: 7.1564 - val_accuracy: 0.2964\nEpoch 15/25\n31934/31934 [==============================] - 22s 686us/step - loss: 0.1887 - accuracy: 0.9398 - val_loss: 7.6575 - val_accuracy: 0.2930\nEpoch 16/25\n31934/31934 [==============================] - 22s 704us/step - loss: 0.1757 - accuracy: 0.9425 - val_loss: 7.7147 - val_accuracy: 0.2975\nEpoch 17/25\n31934/31934 [==============================] - 22s 686us/step - loss: 0.1633 - accuracy: 0.9463 - val_loss: 8.0073 - val_accuracy: 0.2929\nEpoch 18/25\n31934/31934 [==============================] - 22s 681us/step - loss: 0.1705 - accuracy: 0.9462 - val_loss: 7.9701 - val_accuracy: 0.2987\nEpoch 19/25\n31934/31934 [==============================] - 22s 696us/step - loss: 0.1666 - accuracy: 0.9489 - val_loss: 7.7304 - val_accuracy: 0.2999\nEpoch 20/25\n31934/31934 [==============================] - 22s 686us/step - loss: 0.1450 - accuracy: 0.9537 - val_loss: 8.3870 - val_accuracy: 0.2944\nEpoch 21/25\n31934/31934 [==============================] - 22s 683us/step - loss: 0.1459 - accuracy: 0.9532 - val_loss: 8.1455 - val_accuracy: 0.3024\nEpoch 22/25\n31934/31934 [==============================] - 22s 694us/step - loss: 0.1447 - accuracy: 0.9547 - val_loss: 8.3260 - val_accuracy: 0.3012\nEpoch 23/25\n31934/31934 [==============================] - 22s 681us/step - loss: 0.1409 - accuracy: 0.9566 - val_loss: 9.2066 - val_accuracy: 0.2930\nEpoch 24/25\n31934/31934 [==============================] - 22s 686us/step - loss: 0.1401 - accuracy: 0.9575 - val_loss: 8.9436 - val_accuracy: 0.2910\nEpoch 25/25\n31934/31934 [==============================] - 22s 692us/step - loss: 0.1366 - accuracy: 0.9583 - val_loss: 9.1166 - val_accuracy: 0.2965\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}