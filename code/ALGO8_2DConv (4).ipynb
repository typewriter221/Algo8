{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport os\nimport numpy as np \nimport pandas as pd\nfrom numpy import mean\nfrom numpy import std\nfrom numpy import dstack\nfrom numpy import concatenate\nfrom pandas import read_csv\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import Dropout\nfrom keras.layers import LSTM\nfrom keras.utils import to_categorical\nfrom matplotlib import pyplot\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nimport keras\nimport tensorflow as tf\nimport scipy.stats as stats\nfrom tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\nimport tensorflow as tf\nimport keras.backend.tensorflow_backend as tfback\nfrom keras.layers import  Reshape\nfrom keras.layers import Conv2D, MaxPooling2D\ndef _get_available_gpus():\n    \"\"\"Get a list of available gpu devices (formatted as strings).\n\n    # Returns\n        A list of available GPU devices.\n    \"\"\"\n    #global _LOCAL_DEVICES\n    if tfback._LOCAL_DEVICES is None:\n        devices = tf.config.list_logical_devices()\n        tfback._LOCAL_DEVICES = [x.name for x in devices]\n    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n\ntfback._get_available_gpus = _get_available_gpus\n\n\n# # detect and init the TPU\n# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n# tf.config.experimental_connect_to_cluster(tpu)\n# tf.tpu.experimental.initialize_tpu_system(tpu)\n\n# # instantiate a distribution strategy\n# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n\n\n\n\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":4,"outputs":[{"output_type":"stream","text":"[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 168383169270948394\n, name: \"/device:XLA_CPU:0\"\ndevice_type: \"XLA_CPU\"\nmemory_limit: 17179869184\nlocality {\n}\nincarnation: 5350449568911553072\nphysical_device_desc: \"device: XLA_CPU device\"\n, name: \"/device:GPU:0\"\ndevice_type: \"GPU\"\nmemory_limit: 15870492672\nlocality {\n  bus_id: 1\n  links {\n  }\n}\nincarnation: 13580189402401540006\nphysical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n, name: \"/device:XLA_GPU:0\"\ndevice_type: \"XLA_GPU\"\nmemory_limit: 17179869184\nlocality {\n}\nincarnation: 3275318100798388698\nphysical_device_desc: \"device: XLA_GPU device\"\n]\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"os.chdir('/kaggle/input/smartphone-and-smartwatch-activity-and-biometrics/wisdm-dataset/wisdm-dataset/raw/')\n\n# %% [code]\n\n# load a single file as a numpy array\ndef load_file(filepath):\n    dataframe = read_csv(filepath,sep = ',', header=None)\n    return dataframe.to_numpy()\n \n# load a list of files and return as a 3d numpy array\ndef load_group(filenames, prefix=''):\n    loaded = list()\n    for name in filenames:\n        data = load_file(prefix + name)\n        loaded.append(data)\n    # stack group so that features are the 3rd dimension\n    loaded = concatenate(loaded)\n    return loaded\n \n# load a dataset group, such as train or test\ndef load_dataset_group(sample='', prefix='',sensor='',recorder=''):\n#     sensor = 'accel'\n#     recorder = 'phone'\n    filepath = recorder +'/'+ sensor +'/'\n    # load all 9 files as a single array\n    filenames = list()\n    # total acceleration\n   \n    filenames += ['data_'+sample+'_'+sensor+'_'+recorder+'.txt']\n            \n    for filename in filenames:\n        df = load_file(filepath+filename)\n    return df\n \n# load the dataset, returns train and test X and y elements\ndef load_dataset(prefix=''):\n    # load all train\n    prefix = ''\n    dataSampleTrain = list()\n    recorder = ['phone','watch']\n    sensor  = ['accel','gyro']\n    for i in range (1600,1634):\n        size = 99999\n        data = list()\n        for rec in recorder:\n            for sens in sensor:\n                DS = load_dataset_group(str(i), prefix,sens,rec)\n                size = min(size,DS.shape[0])\n                data.append(DS)\n        \n        \n            \n        for i in range(4):\n            data[i] = data[i][:size]\n        dataSampleTrain.append(concatenate(data, axis = 1))\n        \n    \n    dataSampleTrain = concatenate(dataSampleTrain)\n    Traindf = pd.DataFrame(dataSampleTrain)\n    #Traindf.to_csv('TrainDF.csv')\n    \n    dataSampleTest = list() \n    for i in range (1634,1651):\n        size = 99999\n        data = list()\n        for rec in recorder:\n            for sens in sensor:\n                DS = load_dataset_group(str(i), prefix,sens,rec)\n                size = min(size,DS.shape[0])\n                data.append(DS)\n        \n        \n            \n        for i in range(4):\n            data[i] = data[i][:size]\n        dataSampleTest.append(concatenate(data, axis = 1))\n        \n    \n    dataSampleTest = concatenate(dataSampleTest)\n    Testdf = pd.DataFrame(dataSampleTest)\n    #Traindf.to_csv('TrainDF.csv')\n    \n    return Traindf,Testdf\n\n\nwith tf.device('/device:GPU:0'):\n    trainDS,testDS = load_dataset('')\n    trainDS.head()","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess and load X\ndef X_pre(trainDS):\n    \n    \n    cols = [5,11,17,23]\n    for col in cols:\n            trainDS[trainDS.columns[col]] = trainDS[trainDS.columns[col]].str.replace(';','').astype(float)\n    \n    columns = ['x','y','z']\n    X = pd.DataFrame(data=None, columns=columns)\n    X['x'] = trainDS[3]+trainDS[9]+trainDS[15]+trainDS[21]\n    X['y'] = trainDS[4]+trainDS[10]+trainDS[16]+trainDS[22]\n    X['z'] = trainDS[5]+trainDS[11]+trainDS[17]+trainDS[23]\n    \n    # train the normalization\n    scaler = StandardScaler()\n    X = scaler.fit_transform(X)\n\n    return X\nwith tf.device('/device:GPU:0'):\n    trainX = X_pre(trainDS)\n    testX = X_pre(testDS)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess and load Y\n\ndef Y_pre(trainDS):\n    cols = [1,7,13,19]\n    Y = np.zeros((trainDS.shape[0]),dtype=int)\n\n    lable_encoder = LabelEncoder()\n\n    pos = list()\n    for col in cols:\n        y = trainDS[col]\n        y = lable_encoder.fit_transform(y)\n        pos.append(y)\n\n    pos = np.vstack((pos))\n\n    for i in range (trainDS.shape[0]):\n        Y[i] = np.bincount(pos[:,i]).argmax()\n\n    return Y\nwith tf.device('/device:GPU:0'):\n    trainY = Y_pre(trainDS)\n    testY = Y_pre(testDS)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Fs=20\nframe_size = Fs*4 #80\nhop_size = Fs*2 #40","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_frames(df,tag, frame_size, hop_size):\n    \n    N_FEATURES = df.shape[1]\n    frames = []\n    labels = []\n    for i in range(0,len(df )- frame_size, hop_size):\n        x1 = df[i: i+frame_size,0]\n        y1 = df[i: i+frame_size,1]\n        z1 = df[i: i+frame_size,2]\n        \n        label = stats.mode(tag[i: i+frame_size])[0][0]\n        frames.append([x1,y1,z1])\n        labels.append(label)\n        \n    frames = np.asarray(frames).reshape(-1, frame_size, N_FEATURES)\n    labels = np.asarray(labels)\n    \n    return frames, labels","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.device('/device:GPU:0'):\n\n    train_X,train_Y = get_frames(trainX,trainY, frame_size, hop_size)\n    test_X,test_Y = get_frames(testX,testY, frame_size, hop_size)\n    trainx = train_X.reshape(train_X.shape[0], 80, 3,1)\n    testx = test_X.reshape(test_X.shape[0], 80, 3,1)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nx_train,y_train,x_test,y_test = trainx,train_Y,testx,test_Y\nwith tf.device('/device:GPU:0'):\n    #batch_size = 12\n    model = Sequential()\n    model.add(Conv2D(256, (2,2), activation = 'relu', input_shape = x_train[0].shape))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(512, (2,2), activation = 'relu'))\n    model.add(Dropout(0.5))\n\n    model.add(Flatten())\n\n    model.add(Dense(1024, activation = 'relu'))\n    model.add(Dropout(0.5))\n\n    model.add(Dense(18, activation='softmax'))\n    \n    model.compile(optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]) \n    history = model.fit(x_train, y_train, epochs = 25, validation_data=(x_test, y_test), verbose=1 )\n    \n    ","execution_count":12,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Input 0 is incompatible with layer conv2d_1: expected ndim=4, found ndim=2","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-e862a96d0b3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#batch_size = 12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                     \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv2d_1: expected ndim=4, found ndim=2"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}