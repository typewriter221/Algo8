{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport os\nimport numpy as np \nimport pandas as pd\nfrom numpy import mean\nfrom numpy import std\nfrom numpy import dstack\nfrom numpy import concatenate\nfrom pandas import read_csv\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import Dropout\nfrom keras.layers import LSTM\nfrom keras.utils import to_categorical\nfrom matplotlib import pyplot\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nimport keras\nimport tensorflow as tf\nimport scipy.stats as stats\nfrom tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\nimport tensorflow as tf\nimport keras.backend.tensorflow_backend as tfback\ndef _get_available_gpus():\n    \"\"\"Get a list of available gpu devices (formatted as strings).\n\n    # Returns\n        A list of available GPU devices.\n    \"\"\"\n    #global _LOCAL_DEVICES\n    if tfback._LOCAL_DEVICES is None:\n        devices = tf.config.list_logical_devices()\n        tfback._LOCAL_DEVICES = [x.name for x in devices]\n    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n\ntfback._get_available_gpus = _get_available_gpus\n# from keras import backend as K\n# K.tensorflow_backend._get_available_gpus()\n# config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n# sess = tf.Session(config=config) \n# keras.backend.set_session(sess)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 11856218839252709044\n, name: \"/device:XLA_CPU:0\"\ndevice_type: \"XLA_CPU\"\nmemory_limit: 17179869184\nlocality {\n}\nincarnation: 823418352829809270\nphysical_device_desc: \"device: XLA_CPU device\"\n, name: \"/device:GPU:0\"\ndevice_type: \"GPU\"\nmemory_limit: 15870430413\nlocality {\n  bus_id: 1\n  links {\n  }\n}\nincarnation: 14921595282904841384\nphysical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n, name: \"/device:XLA_GPU:0\"\ndevice_type: \"XLA_GPU\"\nmemory_limit: 17179869184\nlocality {\n}\nincarnation: 10222261640825113207\nphysical_device_desc: \"device: XLA_GPU device\"\n]\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"os.chdir('/kaggle/input/smartphone-and-smartwatch-activity-and-biometrics/wisdm-dataset/wisdm-dataset/raw/')\n\n# %% [code]\n\n# load a single file as a numpy array\ndef load_file(filepath):\n    dataframe = read_csv(filepath,sep = ',', header=None)\n    return dataframe.to_numpy()\n \n# load a list of files and return as a 3d numpy array\ndef load_group(filenames, prefix=''):\n    loaded = list()\n    for name in filenames:\n        data = load_file(prefix + name)\n        loaded.append(data)\n    # stack group so that features are the 3rd dimension\n    loaded = concatenate(loaded)\n    return loaded\n \n# load a dataset group, such as train or test\ndef load_dataset_group(sample='', prefix='',sensor='',recorder=''):\n#     sensor = 'accel'\n#     recorder = 'phone'\n    filepath = recorder +'/'+ sensor +'/'\n    # load all 9 files as a single array\n    filenames = list()\n    # total acceleration\n   \n    filenames += ['data_'+sample+'_'+sensor+'_'+recorder+'.txt']\n            \n    for filename in filenames:\n        df = load_file(filepath+filename)\n    return df\n \n# load the dataset, returns train and test X and y elements\ndef load_dataset(prefix=''):\n    # load all train\n    prefix = ''\n    dataSampleTrain = list()\n    recorder = ['phone','watch']\n    sensor  = ['accel','gyro']\n    for i in range (1600,1620):\n        size = 99999\n        data = list()\n        for rec in recorder:\n            for sens in sensor:\n                DS = load_dataset_group(str(i), prefix,sens,rec)\n                size = min(size,DS.shape[0])\n                data.append(DS)\n        \n        \n            \n        for i in range(4):\n            data[i] = data[i][:size]\n        dataSampleTrain.append(concatenate(data, axis = 1))\n        \n    \n    dataSampleTrain = concatenate(dataSampleTrain)\n    Traindf = pd.DataFrame(dataSampleTrain)\n    #Traindf.to_csv('TrainDF.csv')\n    \n    dataSampleTest = list() \n    for i in range (1620,1634):\n        size = 99999\n        data = list()\n        for rec in recorder:\n            for sens in sensor:\n                DS = load_dataset_group(str(i), prefix,sens,rec)\n                size = min(size,DS.shape[0])\n                data.append(DS)\n        \n        \n            \n        for i in range(4):\n            data[i] = data[i][:size]\n        dataSampleTest.append(concatenate(data, axis = 1))\n        \n    \n    dataSampleTest = concatenate(dataSampleTest)\n    Testdf = pd.DataFrame(dataSampleTest)\n    #Traindf.to_csv('TrainDF.csv')\n    \n    return Traindf,Testdf\ntrainDS,testDS = load_dataset('')\ntrainDS.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"     0  1                2         3        4            5     6  7   \\\n0  1600  A  252207666810782 -0.364761   8.7935   1.0550842;  1600  A   \n1  1600  A  252207717164786  -0.87973  9.76878   1.0169983;  1600  A   \n2  1600  A  252207767518790    2.0015  11.1091    2.619156;  1600  A   \n3  1600  A  252207817872794  0.450623  12.6516  0.18455505;  1600  A   \n4  1600  A  252207868226798  -2.16435  13.9284  -4.4224854;  1600  A   \n\n                8         9   ...              14       15        16  \\\n0  252207918580802  -0.85321  ...  90426708196641  7.09162 -0.591667   \n1  252207968934806 -0.875137  ...  90426757696641  4.97276 -0.158317   \n2  252208019288809 -0.720169  ...  90426807196641  3.25372 -0.191835   \n3  252208069642813  -0.57164  ...  90426856696641  2.80122 -0.155922   \n4  252208119996817 -0.380493  ...  90426906196641  3.77087  -1.05135   \n\n           17    18 19              20         21        22              23  \n0   8.195502;  1600  A  90426757696641   0.314944  -1.02228     -0.3099616;  \n1  6.6967316;  1600  A  90426807196641   0.387382 -0.618541   -0.048971802;  \n2   6.107758;  1600  A  90426856696641  0.0709985  -0.20948     -0.1959783;  \n3   5.997625;  1600  A  90426906196641  0.0379753  0.254976     -0.1565635;  \n4   7.731027;  1600  A  90426955696641  0.0731291  0.719431  -0.0010349044;  \n\n[5 rows x 24 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1600</td>\n      <td>A</td>\n      <td>252207666810782</td>\n      <td>-0.364761</td>\n      <td>8.7935</td>\n      <td>1.0550842;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>252207918580802</td>\n      <td>-0.85321</td>\n      <td>...</td>\n      <td>90426708196641</td>\n      <td>7.09162</td>\n      <td>-0.591667</td>\n      <td>8.195502;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>90426757696641</td>\n      <td>0.314944</td>\n      <td>-1.02228</td>\n      <td>-0.3099616;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1600</td>\n      <td>A</td>\n      <td>252207717164786</td>\n      <td>-0.87973</td>\n      <td>9.76878</td>\n      <td>1.0169983;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>252207968934806</td>\n      <td>-0.875137</td>\n      <td>...</td>\n      <td>90426757696641</td>\n      <td>4.97276</td>\n      <td>-0.158317</td>\n      <td>6.6967316;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>90426807196641</td>\n      <td>0.387382</td>\n      <td>-0.618541</td>\n      <td>-0.048971802;</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1600</td>\n      <td>A</td>\n      <td>252207767518790</td>\n      <td>2.0015</td>\n      <td>11.1091</td>\n      <td>2.619156;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>252208019288809</td>\n      <td>-0.720169</td>\n      <td>...</td>\n      <td>90426807196641</td>\n      <td>3.25372</td>\n      <td>-0.191835</td>\n      <td>6.107758;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>90426856696641</td>\n      <td>0.0709985</td>\n      <td>-0.20948</td>\n      <td>-0.1959783;</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1600</td>\n      <td>A</td>\n      <td>252207817872794</td>\n      <td>0.450623</td>\n      <td>12.6516</td>\n      <td>0.18455505;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>252208069642813</td>\n      <td>-0.57164</td>\n      <td>...</td>\n      <td>90426856696641</td>\n      <td>2.80122</td>\n      <td>-0.155922</td>\n      <td>5.997625;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>90426906196641</td>\n      <td>0.0379753</td>\n      <td>0.254976</td>\n      <td>-0.1565635;</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1600</td>\n      <td>A</td>\n      <td>252207868226798</td>\n      <td>-2.16435</td>\n      <td>13.9284</td>\n      <td>-4.4224854;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>252208119996817</td>\n      <td>-0.380493</td>\n      <td>...</td>\n      <td>90426906196641</td>\n      <td>3.77087</td>\n      <td>-1.05135</td>\n      <td>7.731027;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>90426955696641</td>\n      <td>0.0731291</td>\n      <td>0.719431</td>\n      <td>-0.0010349044;</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess and load X\ndef X_pre(trainDS):\n    \n    \n    cols = [5,11,17,23]\n    for col in cols:\n            trainDS[trainDS.columns[col]] = trainDS[trainDS.columns[col]].str.replace(';','').astype(float)\n    #cols = [0,1,2,6,7,8,12,13,14,18,19,20]\n    columns = ['x','y','z']\n    X = pd.DataFrame(data=None, columns=columns)\n    X['x'] = trainDS[3]+trainDS[9]+trainDS[15]+trainDS[21]\n    X['y'] = trainDS[4]+trainDS[10]+trainDS[16]+trainDS[22]\n    X['z'] = trainDS[5]+trainDS[11]+trainDS[17]+trainDS[23]\n#     X = trainDS.drop(trainDS.columns[cols],axis=1)\n    # train the normalization\n\n#     # Iterate over the index range from o to max number of columns in dataframe\n#     for index in range(X.shape[1]):\n#         # Select column by index position using iloc[]\n#         values = X.values[: , index]\n#         values = values.reshape((X.shape[0], 1))\n#         #values = values.reshape(-1, 1)\n#         # normalize the dataset and print\n#         #scaler = MinMaxScaler(feature_range=(0, 1))\n#         scaler = StandardScaler()\n#         scaler = scaler.fit(values)\n#         X.iloc[:,index] = scaler.transform(values)\n\n#     X = balanced_data[['x','y','z']]\n#     y = balanced_data['label']\n    scaler = StandardScaler()\n    X = scaler.fit_transform(X)\n#     scaled_x = pd.DataFrame(data=X, columns=['x','y','z'])\n\n\n\n\n\n    #X = X.values\n#     samples = X.shape[0]\n#     features = X.shape[1]\n#     X = X.reshape(1,samples,features)\n    return X\n#X.head()\ntrainX = X_pre(trainDS)\ntestX = X_pre(testDS)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess and load Y\n\ndef Y_pre(trainDS):\n    cols = [1,7,13,19]\n    Y = np.zeros((trainDS.shape[0]),dtype=int)\n\n    lable_encoder = LabelEncoder()\n\n    pos = list()\n    for col in cols:\n        y = trainDS[col]\n        y = lable_encoder.fit_transform(y)\n        pos.append(y)\n\n    pos = np.vstack((pos))\n\n    for i in range (trainDS.shape[0]):\n        Y[i] = np.bincount(pos[:,i]).argmax()\n    Y.resize(Y.shape[0],1)\n    Y = Y.transpose()\n    return Y\n\ntrainY = Y_pre(trainDS)\ntestY = Y_pre(testDS)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Fs=20\nframe_size = Fs*4 #80\nhop_size = Fs*2 #40","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_frames(df,tag, frame_size, hop_size):\n    \n    N_FEATURES = df.shape[1]\n    frames = []\n    labels = []\n    for i in range(0,len(df )- frame_size, hop_size):\n        x = df[i: i+frame_size,0]\n        y = df[i: i+frame_size,1]\n        z = df[i: i+frame_size,2]\n        \n        label = stats.mode(tag[i: i+frame_size])[0][0]\n        frames.append([x,y,z])\n        labels.append(label)\n        \n    frames = np.asarray(frames).reshape(-1, frame_size, N_FEATURES)\n    labels = np.asarray(labels)\n    \n    return frames, labels","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transY = trainY.transpose()\ntrans_testY = testY.transpose()\ntransY.shape","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"(1277436, 1)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.device('/device:GPU:0'):\n    train_X,train_Y = get_frames(trainX,transY, frame_size, hop_size)\n    test_X,test_Y = get_frames(testX,trans_testY, frame_size, hop_size)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_Y.shape","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"(23638, 1)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainx = train_X.reshape(train_X.shape[0], 80, 3,1)\ntestx = test_X.reshape(test_X.shape[0], 80, 3,1)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testx.shape,test_Y.shape","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"((23638, 80, 3, 1), (23638, 1))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate_model(x_train,y_train,x_test,y_test):\n    \n    model = Sequential()\n    model.add(Conv2D(256, (2,2), activation = 'relu', input_shape = x_train[0].shape))\n    model.add(Dropout(0.1))\n\n    model.add(Conv2D(512, (2,2), activation = 'relu'))\n    model.add(Dropout(0.2))\n\n    model.add(Flatten())\n\n    model.add(Dense(1024, activation = 'relu'))\n    model.add(Dropout(0.5))\n\n    model.add(Dense(18, activation='softmax'))\n    \n    model.compile(optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]) \n    history = model.fit(x_train, y_train, epochs = 25, validation_data=(x_test, y_test), verbose=1 )\n    return history","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import tensorflow as tf\n# # detect and init the TPU\n# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n# tf.config.experimental_connect_to_cluster(tpu)\n# tf.tpu.experimental.initialize_tpu_system(tpu)\n\n# # instantiate a distribution strategy\n# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nfrom keras.layers import  Reshape\nfrom keras.layers import Conv2D, MaxPooling2D\nwith tf.device('/device:GPU:0'):\n# with tpu_strategy.scope():\n    evaluate = evaluate_model(trainx,train_Y,testx,test_Y)","execution_count":24,"outputs":[{"output_type":"stream","text":"Train on 31934 samples, validate on 23638 samples\nEpoch 1/25\n31934/31934 [==============================] - 27s 841us/step - loss: 1.7291 - accuracy: 0.4096 - val_loss: 2.5673 - val_accuracy: 0.2745\nEpoch 2/25\n31934/31934 [==============================] - 22s 699us/step - loss: 1.1079 - accuracy: 0.6191 - val_loss: 2.9967 - val_accuracy: 0.2843\nEpoch 3/25\n31934/31934 [==============================] - 23s 710us/step - loss: 0.8405 - accuracy: 0.7110 - val_loss: 3.7110 - val_accuracy: 0.2849\nEpoch 4/25\n31934/31934 [==============================] - 22s 700us/step - loss: 0.6837 - accuracy: 0.7683 - val_loss: 3.9167 - val_accuracy: 0.2816\nEpoch 5/25\n31934/31934 [==============================] - 23s 708us/step - loss: 0.5854 - accuracy: 0.8017 - val_loss: 3.9698 - val_accuracy: 0.2818\nEpoch 6/25\n31934/31934 [==============================] - 22s 700us/step - loss: 0.4919 - accuracy: 0.8344 - val_loss: 4.3254 - val_accuracy: 0.2944\nEpoch 7/25\n31934/31934 [==============================] - 22s 697us/step - loss: 0.4343 - accuracy: 0.8538 - val_loss: 4.6271 - val_accuracy: 0.2937\nEpoch 8/25\n31934/31934 [==============================] - 23s 710us/step - loss: 0.3948 - accuracy: 0.8671 - val_loss: 5.1495 - val_accuracy: 0.2868\nEpoch 9/25\n31934/31934 [==============================] - 22s 701us/step - loss: 0.3467 - accuracy: 0.8821 - val_loss: 5.2139 - val_accuracy: 0.2839\nEpoch 10/25\n31934/31934 [==============================] - 22s 704us/step - loss: 0.3270 - accuracy: 0.8893 - val_loss: 5.2482 - val_accuracy: 0.2870\nEpoch 11/25\n31934/31934 [==============================] - 23s 707us/step - loss: 0.3131 - accuracy: 0.8938 - val_loss: 5.8493 - val_accuracy: 0.2862\nEpoch 12/25\n31934/31934 [==============================] - 22s 697us/step - loss: 0.2861 - accuracy: 0.9047 - val_loss: 6.0476 - val_accuracy: 0.2927\nEpoch 13/25\n31934/31934 [==============================] - 23s 713us/step - loss: 0.2752 - accuracy: 0.9065 - val_loss: 5.9512 - val_accuracy: 0.3014\nEpoch 14/25\n31934/31934 [==============================] - 22s 702us/step - loss: 0.2536 - accuracy: 0.9126 - val_loss: 6.5224 - val_accuracy: 0.2906\nEpoch 15/25\n31934/31934 [==============================] - 22s 699us/step - loss: 0.2410 - accuracy: 0.9193 - val_loss: 6.0323 - val_accuracy: 0.3099\nEpoch 16/25\n31934/31934 [==============================] - 23s 713us/step - loss: 0.2418 - accuracy: 0.9217 - val_loss: 6.4219 - val_accuracy: 0.3010\nEpoch 17/25\n31934/31934 [==============================] - 22s 695us/step - loss: 0.2170 - accuracy: 0.9261 - val_loss: 6.9424 - val_accuracy: 0.3079\nEpoch 18/25\n31934/31934 [==============================] - 22s 698us/step - loss: 0.2022 - accuracy: 0.9320 - val_loss: 6.8970 - val_accuracy: 0.2911\nEpoch 19/25\n31934/31934 [==============================] - 23s 712us/step - loss: 0.2065 - accuracy: 0.9335 - val_loss: 7.4017 - val_accuracy: 0.2867\nEpoch 20/25\n31934/31934 [==============================] - 22s 697us/step - loss: 0.1917 - accuracy: 0.9359 - val_loss: 7.6785 - val_accuracy: 0.2884\nEpoch 21/25\n31934/31934 [==============================] - 23s 721us/step - loss: 0.1932 - accuracy: 0.9367 - val_loss: 6.8916 - val_accuracy: 0.3024\nEpoch 22/25\n31934/31934 [==============================] - 23s 708us/step - loss: 0.1886 - accuracy: 0.9398 - val_loss: 7.6843 - val_accuracy: 0.2924\nEpoch 23/25\n31934/31934 [==============================] - 22s 698us/step - loss: 0.1734 - accuracy: 0.9422 - val_loss: 7.6343 - val_accuracy: 0.2978\nEpoch 24/25\n31934/31934 [==============================] - 23s 716us/step - loss: 0.1731 - accuracy: 0.9455 - val_loss: 8.2296 - val_accuracy: 0.3013\nEpoch 25/25\n31934/31934 [==============================] - 22s 700us/step - loss: 0.1689 - accuracy: 0.9471 - val_loss: 8.0043 - val_accuracy: 0.3038\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
