{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport os\nimport numpy as np \nimport pandas as pd\nfrom numpy import mean\nfrom numpy import std\nfrom numpy import dstack\nfrom numpy import concatenate\nfrom pandas import read_csv\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import Dropout\nfrom keras.layers import LSTM\nfrom keras.utils import to_categorical\nfrom matplotlib import pyplot\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nimport keras\nimport tensorflow as tf\nimport scipy.stats as stats\nfrom tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\nimport tensorflow as tf\nimport keras.backend.tensorflow_backend as tfback\nfrom keras.layers import  Reshape\nfrom keras.layers import Conv2D, MaxPooling2D\ndef _get_available_gpus():\n    \"\"\"Get a list of available gpu devices (formatted as strings).\n\n    # Returns\n        A list of available GPU devices.\n    \"\"\"\n    #global _LOCAL_DEVICES\n    if tfback._LOCAL_DEVICES is None:\n        devices = tf.config.list_logical_devices()\n        tfback._LOCAL_DEVICES = [x.name for x in devices]\n    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n\ntfback._get_available_gpus = _get_available_gpus\n# from keras import backend as K\n# K.tensorflow_backend._get_available_gpus()\n# config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n# sess = tf.Session(config=config) \n# keras.backend.set_session(sess)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":2,"outputs":[{"output_type":"stream","text":"[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 4289755599607155714\n, name: \"/device:XLA_CPU:0\"\ndevice_type: \"XLA_CPU\"\nmemory_limit: 17179869184\nlocality {\n}\nincarnation: 7235272160524757301\nphysical_device_desc: \"device: XLA_CPU device\"\n, name: \"/device:GPU:0\"\ndevice_type: \"GPU\"\nmemory_limit: 15870492672\nlocality {\n  bus_id: 1\n  links {\n  }\n}\nincarnation: 16929678851612681462\nphysical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n, name: \"/device:XLA_GPU:0\"\ndevice_type: \"XLA_GPU\"\nmemory_limit: 17179869184\nlocality {\n}\nincarnation: 10745395968577157780\nphysical_device_desc: \"device: XLA_GPU device\"\n]\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"os.chdir('/kaggle/input/smartphone-and-smartwatch-activity-and-biometrics/wisdm-dataset/wisdm-dataset/raw/')\n\n# %% [code]\n\n# load a single file as a numpy array\ndef load_file(filepath):\n    dataframe = read_csv(filepath,sep = ',', header=None)\n    return dataframe.to_numpy()\n \n# load a list of files and return as a 3d numpy array\ndef load_group(filenames, prefix=''):\n    loaded = list()\n    for name in filenames:\n        data = load_file(prefix + name)\n        loaded.append(data)\n    # stack group so that features are the 3rd dimension\n    loaded = concatenate(loaded)\n    return loaded\n \n# load a dataset group, such as train or test\ndef load_dataset_group(sample='', prefix='',sensor='',recorder=''):\n#     sensor = 'accel'\n#     recorder = 'phone'\n    filepath = recorder +'/'+ sensor +'/'\n    # load all 9 files as a single array\n    filenames = list()\n    # total acceleration\n   \n    filenames += ['data_'+sample+'_'+sensor+'_'+recorder+'.txt']\n            \n    for filename in filenames:\n        df = load_file(filepath+filename)\n    return df\n \n# load the dataset, returns train and test X and y elements\ndef load_dataset(prefix=''):\n    # load all train\n    prefix = ''\n    dataSampleTrain = list()\n    recorder = ['phone','watch']\n    sensor  = ['accel','gyro']\n    for i in range (1600,1620):\n        size = 99999\n        data = list()\n        for rec in recorder:\n            for sens in sensor:\n                DS = load_dataset_group(str(i), prefix,sens,rec)\n                size = min(size,DS.shape[0])\n                data.append(DS)\n        \n        \n            \n        for i in range(4):\n            data[i] = data[i][:size]\n        dataSampleTrain.append(concatenate(data, axis = 1))\n        \n    \n    dataSampleTrain = concatenate(dataSampleTrain)\n    Traindf = pd.DataFrame(dataSampleTrain)\n    #Traindf.to_csv('TrainDF.csv')\n    \n    dataSampleTest = list() \n    for i in range (1620,1634):\n        size = 99999\n        data = list()\n        for rec in recorder:\n            for sens in sensor:\n                DS = load_dataset_group(str(i), prefix,sens,rec)\n                size = min(size,DS.shape[0])\n                data.append(DS)\n        \n        \n            \n        for i in range(4):\n            data[i] = data[i][:size]\n        dataSampleTest.append(concatenate(data, axis = 1))\n        \n    \n    dataSampleTest = concatenate(dataSampleTest)\n    Testdf = pd.DataFrame(dataSampleTest)\n    #Traindf.to_csv('TrainDF.csv')\n    \n    return Traindf,Testdf\ntrainDS,testDS = load_dataset('')\ntrainDS.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"     0  1                2         3        4            5     6  7   \\\n0  1600  A  252207666810782 -0.364761   8.7935   1.0550842;  1600  A   \n1  1600  A  252207717164786  -0.87973  9.76878   1.0169983;  1600  A   \n2  1600  A  252207767518790    2.0015  11.1091    2.619156;  1600  A   \n3  1600  A  252207817872794  0.450623  12.6516  0.18455505;  1600  A   \n4  1600  A  252207868226798  -2.16435  13.9284  -4.4224854;  1600  A   \n\n                8         9   ...              14       15        16  \\\n0  252207918580802  -0.85321  ...  90426708196641  7.09162 -0.591667   \n1  252207968934806 -0.875137  ...  90426757696641  4.97276 -0.158317   \n2  252208019288809 -0.720169  ...  90426807196641  3.25372 -0.191835   \n3  252208069642813  -0.57164  ...  90426856696641  2.80122 -0.155922   \n4  252208119996817 -0.380493  ...  90426906196641  3.77087  -1.05135   \n\n           17    18 19              20         21        22              23  \n0   8.195502;  1600  A  90426757696641   0.314944  -1.02228     -0.3099616;  \n1  6.6967316;  1600  A  90426807196641   0.387382 -0.618541   -0.048971802;  \n2   6.107758;  1600  A  90426856696641  0.0709985  -0.20948     -0.1959783;  \n3   5.997625;  1600  A  90426906196641  0.0379753  0.254976     -0.1565635;  \n4   7.731027;  1600  A  90426955696641  0.0731291  0.719431  -0.0010349044;  \n\n[5 rows x 24 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1600</td>\n      <td>A</td>\n      <td>252207666810782</td>\n      <td>-0.364761</td>\n      <td>8.7935</td>\n      <td>1.0550842;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>252207918580802</td>\n      <td>-0.85321</td>\n      <td>...</td>\n      <td>90426708196641</td>\n      <td>7.09162</td>\n      <td>-0.591667</td>\n      <td>8.195502;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>90426757696641</td>\n      <td>0.314944</td>\n      <td>-1.02228</td>\n      <td>-0.3099616;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1600</td>\n      <td>A</td>\n      <td>252207717164786</td>\n      <td>-0.87973</td>\n      <td>9.76878</td>\n      <td>1.0169983;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>252207968934806</td>\n      <td>-0.875137</td>\n      <td>...</td>\n      <td>90426757696641</td>\n      <td>4.97276</td>\n      <td>-0.158317</td>\n      <td>6.6967316;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>90426807196641</td>\n      <td>0.387382</td>\n      <td>-0.618541</td>\n      <td>-0.048971802;</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1600</td>\n      <td>A</td>\n      <td>252207767518790</td>\n      <td>2.0015</td>\n      <td>11.1091</td>\n      <td>2.619156;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>252208019288809</td>\n      <td>-0.720169</td>\n      <td>...</td>\n      <td>90426807196641</td>\n      <td>3.25372</td>\n      <td>-0.191835</td>\n      <td>6.107758;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>90426856696641</td>\n      <td>0.0709985</td>\n      <td>-0.20948</td>\n      <td>-0.1959783;</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1600</td>\n      <td>A</td>\n      <td>252207817872794</td>\n      <td>0.450623</td>\n      <td>12.6516</td>\n      <td>0.18455505;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>252208069642813</td>\n      <td>-0.57164</td>\n      <td>...</td>\n      <td>90426856696641</td>\n      <td>2.80122</td>\n      <td>-0.155922</td>\n      <td>5.997625;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>90426906196641</td>\n      <td>0.0379753</td>\n      <td>0.254976</td>\n      <td>-0.1565635;</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1600</td>\n      <td>A</td>\n      <td>252207868226798</td>\n      <td>-2.16435</td>\n      <td>13.9284</td>\n      <td>-4.4224854;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>252208119996817</td>\n      <td>-0.380493</td>\n      <td>...</td>\n      <td>90426906196641</td>\n      <td>3.77087</td>\n      <td>-1.05135</td>\n      <td>7.731027;</td>\n      <td>1600</td>\n      <td>A</td>\n      <td>90426955696641</td>\n      <td>0.0731291</td>\n      <td>0.719431</td>\n      <td>-0.0010349044;</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess and load X\ndef X_pre(trainDS):\n    \n    \n    cols = [5,11,17,23]\n    for col in cols:\n            trainDS[trainDS.columns[col]] = trainDS[trainDS.columns[col]].str.replace(';','').astype(float)\n    \n    columns = ['x','y','z']\n    X = pd.DataFrame(data=None, columns=columns)\n    X['x'] = trainDS[3]+trainDS[9]+trainDS[15]+trainDS[21]\n    X['y'] = trainDS[4]+trainDS[10]+trainDS[16]+trainDS[22]\n    X['z'] = trainDS[5]+trainDS[11]+trainDS[17]+trainDS[23]\n    \n    # train the normalization\n    scaler = StandardScaler()\n    X = scaler.fit_transform(X)\n\n    return X\n\ntrainX = X_pre(trainDS)\ntestX = X_pre(testDS)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess and load Y\n\ndef Y_pre(trainDS):\n    cols = [1,7,13,19]\n    Y = np.zeros((trainDS.shape[0]),dtype=int)\n\n    lable_encoder = LabelEncoder()\n\n    pos = list()\n    for col in cols:\n        y = trainDS[col]\n        y = lable_encoder.fit_transform(y)\n        pos.append(y)\n\n    pos = np.vstack((pos))\n\n    for i in range (trainDS.shape[0]):\n        Y[i] = np.bincount(pos[:,i]).argmax()\n\n    return Y\n\ntrainY = Y_pre(trainDS)\ntestY = Y_pre(testDS)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Fs=20\nframe_size = Fs*4 #80\nhop_size = Fs*2 #40","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_frames(df,tag, frame_size, hop_size):\n    \n    N_FEATURES = df.shape[1]\n    frames = []\n    labels = []\n    for i in range(0,len(df )- frame_size, hop_size):\n        x1 = df[i: i+frame_size,0]\n        y1 = df[i: i+frame_size,1]\n        z1 = df[i: i+frame_size,2]\n        \n        label = stats.mode(tag[i: i+frame_size])[0][0]\n        frames.append([x1,y1,z1])\n        labels.append(label)\n        \n    frames = np.asarray(frames).reshape(-1, frame_size, N_FEATURES)\n    labels = np.asarray(labels)\n    \n    return frames, labels","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.device('/device:GPU:0'):\n    train_X,train_Y = get_frames(trainX,trainY, frame_size, hop_size)\n    test_X,test_Y = get_frames(testX,testY, frame_size, hop_size)\n    trainx = train_X.reshape(train_X.shape[0], 80, 3,1)\n    testx = test_X.reshape(test_X.shape[0], 80, 3,1)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nx_train,y_train,x_test,y_test = trainx,train_Y,testx,test_Y\nwith tf.device('/device:GPU:0'):\n    #batch_size = 12\n    model = Sequential()\n    model.add(Conv2D(256, (2,2), activation = 'relu', input_shape = x_train[0].shape))\n    #model.add(Dropout(0.2))\n\n    model.add(Conv2D(512, (2,2), activation = 'relu'))\n    #model.add(Dropout(0.5))\n\n    model.add(Flatten())\n\n    model.add(Dense(1024, activation = 'relu'))\n    #model.add(Dropout(0.5))\n\n    model.add(Dense(18, activation='softmax'))\n    \n    model.compile(optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]) \n    history = model.fit(x_train, y_train, epochs = 25, validation_data=(x_test, y_test), verbose=1 )\n    ","execution_count":11,"outputs":[{"output_type":"stream","text":"Train on 16096 samples, validate on 23638 samples\nEpoch 1/25\n16096/16096 [==============================] - 17s 1ms/step - loss: 1.7689 - accuracy: 0.4026 - val_loss: 3.1394 - val_accuracy: 0.2249\nEpoch 2/25\n16096/16096 [==============================] - 13s 803us/step - loss: 1.0713 - accuracy: 0.6323 - val_loss: 3.4448 - val_accuracy: 0.2283\nEpoch 3/25\n16096/16096 [==============================] - 13s 805us/step - loss: 0.7936 - accuracy: 0.7327 - val_loss: 3.9186 - val_accuracy: 0.2284\nEpoch 4/25\n 2144/16096 [==>...........................] - ETA: 8s - loss: 0.6130 - accuracy: 0.7836","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-15c6b67aed15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3719\u001b[0m               'You must feed a value for placeholder %s' % (tensor,))\n\u001b[1;32m   3720\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3721\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3722\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3723\u001b[0m         \u001b[0;31m# Temporary workaround due to `convert_to_tensor` not casting floats.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \"\"\"\n\u001b[1;32m    257\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 258\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    264\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
